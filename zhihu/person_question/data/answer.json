{
    "1698758739083": {
        "created_time": 1698758739,
        "content": "自营肥成猪，客户亏成狗~~~美东时间10月29日，华尔街日报(TheWallStreetJournal)发布了独家新闻《HedgeFundTwoSigmaIsHitbyTradingScandal》，指出漂亮国量化巨头TwoSigma深陷交易丑闻。原文地址：https://www.wsj.com/finance/investing/hedge-fund-two-sigma-is-hit-by-trading-scandal-501913cb整个事情的起因是，一个叫JianWu的华人量化研究员，同时也是该公司的高级副总裁(seniorvicepresident)，为了提高自己的收入，未经授权，私自调整了公司的投资模型，在过去的一年中，给公司带来了总计6.2亿美元的意外收入和损失。其中意外收入4.5亿美元，意外损失1.7亿美元，关键是这盈利的部分主要是公司高管和员工投资的自营基金产品，损失的部分是对外募集客户的资金，也就是自营肥成猪，客户亏成狗，不过目前TwoSigma表示，已经将这部分亏损全额赔偿给了客户。从目前披露的信息来看，漂亮国证监会已经介入调查，JianWu本人也被公司停职反省，幸好这是赚了啊，赚的钱还够赔，如果是亏了，后头个人连带责任就赔惨了。查看JianWu的领英账号，本科清华自动化，博士康奈尔运筹学，2016年还在Citadel实习过，2018年4月加入TwoSigma当量化研究员，3年升副总，5年升高级副总，现如今在TwoSigma管理着一个Alpha生成团队，已经是很多华人量化研究员的职业天花板了。光鲜亮丽的教育背景和职业生涯，也给他带来了丰厚的收入，据网友爆料，JianWu在今年年初就在小红书上晒过收入，2022年收入2350万美刀，这不就是对应着那4.5亿美元盈利的提成嘛(按5%计算，外带一点其他收入)，换算成人民币，那是妥妥超过1个小目标了，怪不得要铤而走险，反正都是别人的钱，赢了会所嫩模，输了也不用下海干活。不过整件事情还没有尘埃落定，虽然TwoSigma给客户的信中，将JianWu这种行为描述为“故意不当行为”(intentionalmisconduct)，违反了公司的内部规定，但一位知晓公司内情的内部人员，对公司的说法提出了异议，称JianWu调整的是TwoSigma公司的模型校准(calibration)，并没有改变模型本身，校准变化相对来说是一种常规行为，现在还不知道TwoSigma有没有禁止未经授权对其模型进行校准的政策，感觉最终还是要看漂亮国证监会怎么判了。量化从今年八月底算来，这两个多月都是不断水逆，先是量化私募Boss买上海豪宅惹众怒，后是融资融券被声讨，国内头部量化私募桃色大瓜还没过去，又是一个国外量化巨头华人研究员大瓜当头砸来。套用老舍《茶馆》里的一句话：我爱量化，我怕他完了！更多相关量化内容更多相关资料请见下方文章卡片，另外还有一个周更的量化公Z号『量化君也』，专注于量化策略分享/交流/社群，欢迎来玩~你见过哪些怪异的量化交易策略？你见过哪些耳目一新的量化交易策略？各位推荐一些量化投资的书籍、资料和网站啊？量化模型的建型过程是怎么样的呢？量化君也：复现网红阻力支撑指标RSRS，手把手教你构建大盘择时策略量化君也：261个策略/指标，量化萌新可以在这本量化神作中学到的量化君也：如何打造「量化策略兵器库」，策略开发效率提高10倍？量化新手找因子如何入门？万能的知乎量化，有哪些可以挖掘因子、研发因子、学习新因子的路径？",
        "url": "https://api.zhihu.com/answers/3271889928",
        "voteup_count": 42,
        "thanks_count": 4,
        "question_title": "https://api.zhihu.com/questions/628362798",
        "question_url": "如何评价华人量化交易员私自调整交易模型，获利4.5亿美元、正接受美国证监会调查？",
        "verb": "MEMBER_VOTEUP_ANSWER"
    },
    "1698758683983": {
        "created_time": 1698758683,
        "content": "我说说自己做量化策略研究时，常用的并且效果还不赖的10个机器学习算法吧，会大概讲述其基本工作原理、用法用途和代码案例，主要是给大伙儿起到“算法清单”的作用，篇幅有限，难以面面俱到，还望海涵~一、线性回归(Linearregression)线性回归应该可以说是最常用的一种统计模型了，高中就接触过的最小二乘法OLS就属于线性回归，你瞧，这也算是早期接触机器学习的案例了。线性回归基于一个或多个自变量预测因变量的值，它之所以被称为“线性”，那是因为它假设因变量和自变量之间的关系是线性的，形式如y=a0+a1*x1+a2*x2+...+an*xn，其中x是自变量，y是因变量，a就是回归系数，a0又被称为截距。在金融投资和量化交易领域，线性回归经常被用来建模和预测金融时间序列/横截面数据，比如证券价格、因子收益、汇率和利率等等。它可以用来识别不同变量/因子之间的关系，并基于这些关系对未来值进行预测。线性回归主打的优点就是其简单性和可解释性，不信你瞧，咱常见的资本资产定价模型（CAPM）、套利定价模型（APT）和Fama-French三因子等等模型都是表达成这种形式。线性回归模型除了应用广泛之外，还非常容易实现，即使在大数据集上，它的训练速度也相对较快，并且还可以通过使用虚拟变量来处理缺失数据和分类变量。现在使用这些机器学习算法已经非常方便了，都是封装好的库（例如scikit-learn），直接调用就可以了，下面来看看线性回归的实例源码。importnumpyasnpfromsklearn.linear_modelimportLinearRegression#构建数据样本X=np.array([[1,2],[3,4],[5,6],[7,8]])y=np.array([1,2,3,4])#创建线性回归模型model=LinearRegression()#用数据样本训练模型model.fit(X,y)#用训练好的模型去预测样本predictions=model.predict(X)#打印输出print(&#39;预测：&#39;,predictions)print(&#39;系数：&#39;,model.coef_)print(&#39;截距：&#39;,model.intercept_)输出结果：预测：[1.2.3.4.]系数：[0.250.25]截距：0.24999999999999956这段代码是对X数组中的数据进行线性回归模型拟合，y数组作为目标变量(因变量)，可以看出X有4个样本点，每个样本有2个特征，会自动学习出2个回归系数和1个截距，最终的训练模型为y=0.25+0.25x1+0.25x2。这里特别说明的是，虽然上面的代码简单，但现在的机器学习库的使用流程基本都是一样的：先从库(sklearn)中导入需要的模型(LinearRegression)，然后导入数据进行训练(fit)，最后便可以使用训练好的模型对新数据进行预测(predict)，如果觉得有需要，可以查看模型的关键参数(coef_和intercept_)。下文所有算法模型的建模流程都是遵循这种三板斧流程，不再赘述。不过一般情况下，训练模型用的数据集称为训练集，给训练好的模型进行预测的数据集称为测试集，两个数据集一般数据是不重叠、没有交集的，咱这里是偷懒了，请注意区分。二、逻辑回归(Logisticregression)不要看到这个算法里面有“回归”(regression)的字样，就以为它是像线性回归那样用来完成回归任务的，其实它主要是被用来完成分类任务的。通常是基于一个或多个自变量预测二元结果的概率。它的模型结构是y=1/(1+exp(a0+a1*x1+a2*x2+...+an*xn))，就是在线性回归的基础上，套上了一层Sigmoid函数y=1/(1+exp(x))，无论exp(*)当中的数值是什么范围，都能将y限制到0~1之间，很好地完成二分类任务。在金融投资和量化交易领域中，逻辑回归就是经常被用于分类任务，例如证券价格是上涨还是下跌、财务报表当中是否存在欺诈行为或者企业净利润率是否超额上升。逻辑回归的主要优势和线性回归一样，实现和解释起来都相对简单，即使在大型数据集上训练也非常快速。除此之外，逻辑回归具有“概率性”的特性，这意味着它可以输出概率形式的预测结果，而不仅仅是二元预测，这一点在量化交易当中非常有用，能衡量其中不确定性或风险水平。咱来看看逻辑回归的使用实例，如下所示，从整个流程来看，跟线性回归模型是一样的，只不过对于分类任务，y的标签数值要改为0或1，用来表示类别。importnumpyasnpfromsklearn.linear_modelimportLogisticRegression#构建数据样本X=np.array([[1,2],[3,4],[5,6],[7,8]])y=np.array([0,1,0,1])#创建逻辑回归模型model=LogisticRegression()#训练模型model.fit(X,y)#对数据进行预测量predictions=model.predict(X)#打印预测结果print(predictions)三、决策树(Decisiontrees)决策树之所以被称为“决策”树，顾名思义，能根据数据集的特征进行预测，它通过数据构建一个类似树状的决策模型来工作，每个分支代表不同的决策或结果。在金融投资和量化交易领域中，决策树通常被用于分类任务。决策树的主要优势除了相对简单易懂和解释较强外，关键它还能够处理复杂的数据集，并能够识别特征与目标变量之间的非线性关系。不过，如果决策树没有经过适当的修剪，可能会出现过拟合的问题，从而降低其泛化能力。决策树的使用案例如下所示，流程跟上面两种算法是一样的，注意是分类任务就好。importnumpyasnpfromsklearn.treeimportDecisionTreeClassifier#构建样本数据X=[[0,0],[1,1]]Y=[0,1]#创建决策树分类器clf=DecisionTreeClassifier()#训练模型clf=clf.fit(X,Y)#打印预测结果print(clf.predict([[2.,2.]]))对了，你还可以指定用于拆分树的准则类型，例如“gini”或“entropy”，并设置其他参数，如树的最大深度或叶节点所需的最小样本数，在scikit-learn文档中可以找到完整描述。https://scikit-learn.org/stable/modules/tree.html四、随机森林(Randomforests)随机森林属于上面刚介绍的决策树的扩展，基于集成学习的原理，用于进行更强大和可靠的预测。它通过创建一组决策树，并使用每棵树所做预测的平均值来进行最终预测，就类似于现实当中咱一群人投票，然后少数服从多数那样。随机森林一般也是被用于分类任务，一般具有比较高的准确性，并且往往比单个决策树具有更好的泛化能力。不过，与单个决策树相比，随机森林的解释性相对差一些，因为预测是基于许多树的平均值，而不是单个树。在使用当中，从sklearn里面导入RandomForestClassifier模型后，需要设置森林中树的数量(n_estimators)，树的最大深度(max_depth)和随机种子(random_state)，其他的部分，就是跟传统的三板斧流程一样的了。importnumpyasnpfromsklearn.ensembleimportRandomForestClassifier#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#创建随机森林模型model=RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)#训练模型model.fit(X_train,y_train)#预测新数据predictions=model.predict(X_test)#打印预测结果print(predictions)需要特别说明的是，load_data()是抽象出来的函数，需要自己根据自身应用情况实现，主要目的是用来加载训练集数据(X_train)和标签(y_train)、测试集数据(X_test)和标签(y_test)，组织形式跟上面介绍过的3个算法是一样的，如果当前自己还没有确切建模任务的话，可以根据我之前的两篇文章《手把手教你，利用机器学习模型，构建量化择时策略》和《投资经理3周须开发4000个量化因子，手把手教你4行核心代码轻松应对》中的数据准备部分构建因子数据和打上对应的标签。手把手教你，利用机器学习模型，构建量化择时策略（附全流程代码）私募奇葩要求，投资经理3周须开发4000个量化因子，手把手教你4行核心代码轻松应对如果也不想自己组织数据，想马上就开箱使用，那可以直接使用sklearn机器学习库datasets模块，里面自带了各种机器学习任务需要用到的数据集，首先你可以使用make_regression或make_classification函数自定义生成自己需要的回归/分类数据集，其次你也可以使用现成的数据集，例如回归任务常用的糖尿病数据集(load_diabetes)，分类任务的鸢尾花数据集(load_iris)。私募奇葩要求，投资经理3周须开发4000个量化因子，手把手教你4行核心代码轻松应对如果也不想自己组织数据，想马上就开箱使用，那可以直接使用sklearn机器学习库datasets模块，里面自带了各种机器学习任务需要用到的数据集，首先你可以使用make_regression或make_classification函数自定义生成自己需要的回归/分类数据集，其次你也可以使用现成的数据集，例如回归任务常用的糖尿病数据集(load_diabetes)，分类任务的鸢尾花数据集(load_iris)。就以随机森林这次的分类任务为例，使用鸢尾花数据集(load_iris)，咱先看一下具体的数据形式。importnumpyasnpimportpandasaspdfromsklearnimportdatasetsiris=datasets.load_iris()#导入鸢尾花数据data=iris[&#39;data&#39;]#数据label=iris[&#39;target&#39;]#数据对应的标签feature=iris[&#39;feature_names&#39;]#特征的名称df=pd.DataFrame(np.column_stack((data,label)),columns=np.append(feature,&#39;label&#39;))df.iloc[[0,1,60,61,120,121],:]#分别展示类别为0、1、2的样本iris包含了150个鸢尾花的数据，其中每个样本有4个特征，分别为萼片长度、萼片宽度、花瓣长度和花瓣宽度，以及对应的类别标签，label的0、1、2分别对应花的品种IrisSetosa、IrisVersicolour、IrisVirginica）。于是乎，要在随机森林当中使用这个数据集来训练和测试模型，只需要将应用实例当中的这句代码#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()修改为fromsklearnimportdatasetsfromsklearn.model_selectionimporttrain_test_split#加载训练集和测试集数据iris=datasets.load_iris()X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,test_size=0.2)为了方便阐述和展示，下文依旧使用抽象函数load_data()表示训练集和测试集数据的加载，不再赘述。五、K最近邻（KNN）K最近邻（K-NearestNeighbors，KNN）是一种常用于分类和回归任务的机器学习算法，它大概的原理是通过找到离给定数据点最近的K个数据点，并利用这些数据点的类别或数值来进行预测。相信大多数人都听过这种说法，“你的收入就是身边5位好友收入的平均值”，KNN贯彻的就是这种“人以群分，物以类聚”的理念。在金融投资和量化交易领域中，KNN通常用于分类任务居多，也可以用于回归。KNN的主要优势之一是相对简单易懂，并且容易实现，对缺失值不太敏感，最大的缺点就是，它对于K值的选择比较敏感。除此之外，在特征/因子数量相对于样本数量过大的情况下可能表现比较拉胯，在大型数据集上进行KNN预测也可能需要比较大的计算量。importnumpyasnpfromsklearn.neighborsimportKNeighborsClassifier#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#创建KNN模型model=KNeighborsClassifier(n_neighbors=5)#训练模型model.fit(X_train,y_train)#预测新数据predictions=model.predict(X_test)#打印预测结果print(predictions)六、K均值聚类算法(K-Means)说完KNN，就顺道儿来说一下它的亲戚K-Means，从称呼上看起来很像，底层原理也很像，但干的却是不一样的活儿。K-Means一般用于聚类(clustering)任务，而KNN一般用于分类(classification)任务，虽然是一字之差，但用途却不一样。咱可以先把实例代码贴出来，你就会发现它跟别的算法代码有个显著的区别。importnumpyasnpfromsklearn.clusterimportKMeans#构建样本数据X=np.array([[1,2],[1,4],[1,0],[4,2],[4,4],[4,0]])#创建KMeans模型model=KMeans(n_clusters=2,random_state=0,n_init=&#39;auto&#39;)#训练模型model.fit(X)#预测新数据predictions=model.predict([[0,0],[4,4]])#打印预测结果print(predictions)看见木有，别的算法一般训练模型时都需要同时输入特征/因子数据X和标签数据y，而K-Means只需要输入特征/因子数据X，前者这种训练方式被称为监督学习(Supervisedlearning)，后者则被称为无监督学习(Unsupervisedlearning)，前者就相当于让你自学的时候，既发给你试题，也发给你参考答案，后者是只发试题，木有答案。那有什么用呢？也是起到“人以群分，物以类聚”的划分作用，因此K-Means叫聚类算法，比如说现在A股有5000多支股票，申万把它们划分为31个行业，你觉得这样划分不合适，可以给它们设定不同的属性/因子和想分成多少个行业/概念/风格/板块(例如上面实例的聚类数是2)，K-Means算法就可以把这5000多支股票按自己的要求划分出来，在每个簇当中，里面的股票在你设定属性/因子方面肯定都是极其相似的，属于你自己的行业/概念/风格/板块。很多时候，你会惊叹，八竿子打不着的股票怎么会在这些方面这么相似。七、支持向量机（SVM）支持向量机（SupportVectorMachines，SVM）最初的设计是用来解决二分类问题，后来扩展到多分类问题，比如说之前开发的大盘择时策略“预测沪深300指数涨跌”就属于典型的二分类问题，“涨”是一个类别，“跌”就是另一个类别。它通过寻找一个最大间隔超平面将两类样本线性区分开来，并且保证两侧样本的最近边缘点到这个平面的距离是最大的，由于最大间隔超平面仅取决于两个类别的边缘点，这些点就被称为支持向量，这就是“支持向量机”名称的由来。如果数据点在原始空间不可分的话，就将低维不可分的数据映射到高维线性可分，于是乎，SVM的主要优势之一就是能够处理高维数据，并且能识别特征与目标变量之间的复杂关系。不过，与其他一些机器学习算法相比，SVM的训练计算量可能更大，并且由于基于复杂的优化问题，解释性就相对差一些。对了，为了将数据从低维映射到高维，SVM中核函数的选取就非常关键，常用的核函数有线性核、多项式核、高斯核（RBF核）和Sigmoid核。importnumpyasnpfromsklearn.svmimportSVC#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#创建SVM模型model=SVC(kernel=&#39;linear&#39;,C=1.0)#训练模型model.fit(X_train,y_train)#预测新数据predictions=model.predict(X_test)#打印预测结果print(predictions)八、朴素贝叶斯(NaiveBayes)朴素贝叶斯是一种基于贝叶斯定理进行预测的机器学习算法，它之所以被称为“朴素”是因为它假设数据集当中的所有特征都是相互独立的，而在现实世界的数据中当然肯定不是这样的。尽管有这个假设，朴素贝叶斯算法通常用起来效果也不错，并且在金融投资和量化交易当中经常使用。朴素贝叶斯算法常被用于分类任务，比如预测指数第二日涨跌、财经新闻的正负面情或者财务报表是否掺假。朴素贝叶斯算法的主要优势之一就是其简单性和易于理解了，就连很多成功学文章和书籍中，都经常倡导要“贝叶斯式”思考。这个模型训练起来也非常快，即使是在大型数据集上。并且，当底层数据受到某些类型的噪声干扰影响，或者特征数量相对于样本数量过大时，朴素贝叶斯算法往往也都有良好表现。importnumpyasnpfromsklearn.naive_bayesimportGaussianNB#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#创建朴素贝叶斯分类器model=GaussianNB()#训练模型model.fit(X_train,y_train)#预测新数据predictions=model.predict(X_test)#打印预测结果print(predictions)九、神经网络(Neuralnetworks)神经网络是一种受到人脑结构和功能启发而研发出来的机器学习算法，模型结构由大量相互连接的节点(神经元)组成，模拟人脑的机制用于处理和传输信息。神经网络特别适用于涉及模式识别和预测的任务，并且已被广泛应用于各种领域和场景，取得了非常显著的成果。神经网络模型在回归和分类任务上都非常支棱，只需要人为地确定模型结构，然后就能够在没有显式编程的情况下学习、迭代和适应新数据，它还可以处理大型和复杂的数据集，并能够识别特征与目标变量之间的非线性关系。与其他一些机器学习算法相比，神经网络的训练可能需要消耗更多的计算资源，并且由于其中复杂的网络结构，因此可解释性就差很多，如果设计和训练不当的话，神经网络非常容易过拟合。importnumpyasnpfromtensorflow.keras.modelsimportSequentialfromtensorflow.keras.layersimportDense#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#创建神经网络分类器model=Sequential()model.add(Dense(8,input_dim=4,activation=&#39;sigmoid&#39;))model.add(Dense(1,activation=&#39;sigmoid&#39;))model.compile(loss=&#39;binary_crossentropy&#39;,optimizer=&#39;adam&#39;,metrics=[&#39;accuracy&#39;])#训练模型model.fit(X_train,y_train,epochs=20,batch_size=32)#预测新数据predictions=model.predict(X_test)#打印预测结果print(predictions)十、集成学习(Ensemblelearning)集成学习(Ensemblelearning)并不是特指某一个算法，而是一个算法大类，或者说是训练和组合模型的思路或方法。在机器学习当中，单个模型运行时可能表现没那么好，但同时将多个模型组合起来，“三个臭皮匠顶个诸葛亮”，就会变得非常强大，这种多个基础模型/算法的组合，就被称为集成学习。集成学习一般分为两大类：Bagging(装袋法)和Boosting(提升法)。这两种方法都是将多个弱模型组合在一起，形成一个强模型，但它们之间最明显的区别是，Bagging中的多个弱模型都是并行单独训练，然后再组合在一起，而Boosting是串行训练，下一级弱模型是根据前一级弱模型的“残差”针对性训练，用来提升上一级的“短板”，最终再组合在一起。其实集成学习还有更为复杂的Stacking(堆叠法)和Cascading(级联法)，有兴趣的话，可以自己去探究一下。Bagging模型结构：Boosting模型结构：Bagging集成学习其实咱之前已经见过了，那就是随机森林，在金融投资和量化交易领域，Bagging用得最多的就是它。Boosting集成学习就比较多了，常见的有：梯度提升树GBDT、自适应提升算法Adaboost、极限梯度提升算法XGBoost和轻量级梯度提升算法LightGBM。以前常用XGBoost组合多因子模型，现在多流行用LightGBM，那就以LightGBM作为实例展示吧。importnumpyasnpimportlightgbmaslgb#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#训练模型gbm=lgb.train(params={&#39;learning_rate&#39;:0.05,&#39;lambda_l1&#39;:0.1,&#39;lambda_l2&#39;:0.2,&#39;max_depth&#39;:3,&#39;objective&#39;:&#39;multiclass&#39;,&#39;num_class&#39;:3},train_set=lgb.Dataset(X_train,label=y_train))#预测新数据predictions=gbm.predict(X_test)predictions=[list(v).index(max(v))forvinpredictions]#打印预测结果print(predictions)量化交易领域的10大常用机器学习算法就盘点完了，不知道你有没有发现，再复杂的机器学习算法，利用现成的机器学习算法库(如sklearn)，按照“三板斧”流程，十几二十行代码就可以建模完毕，麻麻再也不用担心咱的算法实现。这就是本回答想要达到的目的，以后大伙儿大部分时间只需要专注于量化任务拆解和数据整理，是分类任务(如预测涨跌)，还是回归任务(如预测涨跌幅)，接着把特征/因子数据整理好，按照这机器学习算法清单的索引，按需按代码实例使用相应算法就搞掂了，顺藤摸瓜，按图索骥。内容来源/参考：ChristopheAtten，2022.12，《Top10machinelearningalgorithmsinFinance》ChainikaThakar，2023.01，《Top10MachineLearningAlgorithmsForBeginners》机器之心，2019.03，《机器学习必学10大算法》楷哥，2020.10，《集成学习》周志华，2016.01，《机器学习》更多相关资料请见下方文章卡片，另外还有一个持续更新的量化公Z号『量化君也』，专注于量化策略分享/交流/社群，欢迎来玩~量化君也：261个策略/指标，量化萌新可以在这本量化神作中学到的你见过哪些怪异的量化交易策略？你见过哪些耳目一新的量化交易策略？量化模型的建型过程是怎么样的呢？量化君也：如何打造「量化策略兵器库」，策略开发效率提高10倍？量化新手找因子如何入门？万能的知乎量化，有哪些可以挖掘因子、研发因子、学习新因子的路径？量化投资的回测往往不错，但是实盘如何呢？",
        "url": "https://api.zhihu.com/answers/3271883483",
        "voteup_count": 9,
        "thanks_count": 8,
        "question_title": "https://api.zhihu.com/questions/503975991",
        "question_url": "在进行量化策略研究的时候，常用的机器学习模型有哪些？",
        "verb": "MEMBER_VOTEUP_ANSWER"
    },
    "1698717130344": {
        "created_time": 1698717130,
        "content": "美东时间10月29日，华尔街日报(TheWallStreetJournal)发布了独家新闻《HedgeFundTwoSigmaIsHitbyTradingScandal》，指出漂亮国量化巨头TwoSigma深陷交易丑闻。原文地址：https://www.wsj.com/finance/investing/hedge-fund-two-sigma-is-hit-by-trading-scandal-501913cb整个事情的起因是，一个叫JianWu的华人量化研究员，同时也是该公司的高级副总裁(seniorvicepresident)，为了提高自己的收入，未经授权，私自调整了公司的投资模型，在过去的一年中，给公司带来了总计6.2亿美元的意外收入和损失。其中意外收入4.5亿美元，意外损失1.7亿美元，关键是这盈利的部分主要是公司高管和员工投资的自营基金产品，损失的部分是对外募集客户的资金，也就是自营肥成猪，客户亏成狗，不过目前TwoSigma表示，已经将这部分亏损全额赔偿给了客户。从目前披露的信息来看，漂亮国证监会已经介入调查，JianWu本人也被公司停职反省，幸好这是赚了啊，赚的钱还够赔，如果是亏了，后头个人连带责任就赔惨了。查看JianWu的领英账号，本科清华自动化，博士康奈尔运筹学，2016年还在Citadel实习过，2018年4月加入TwoSigma当量化研究员，3年升副总，5年升高级副总，现如今在TwoSigma管理着一个Alpha生成团队，已经是很多华人量化研究员的职业天花板了。光鲜亮丽的教育背景和职业生涯，也给他带来了丰厚的收入，据网友爆料，JianWu在今年年初就在小红书上晒过收入，2022年收入2350万美刀，这不就是对应着那4.5亿美元盈利的提成嘛(按5%计算，外带一点其他收入)，换算成人民币，那是妥妥超过1个小目标了，怪不得要铤而走险，反正都是别人的钱，赢了会所嫩模，输了也不用下海干活。不过整件事情还没有尘埃落定，虽然TwoSigma给客户的信中，将JianWu这种行为描述为“故意不当行为”(intentionalmisconduct)，违反了公司的内部规定，但一位知晓公司内情的内部人员，对公司的说法提出了异议，称JianWu调整的是TwoSigma公司的模型校准(calibration)，并没有改变模型本身，校准变化相对来说是一种常规行为，现在还不知道TwoSigma有没有禁止未经授权对其模型进行校准的政策，感觉最终还是要看漂亮国证监会怎么判了。量化从今年八月底算来，这两个多月都是不断水逆，先是量化私募Boss买上海豪宅惹众怒，后是融资融券被声讨，国内头部量化私募桃色大瓜还没过去，又是一个国外量化巨头华人研究员大瓜当头砸来。套用老舍《茶馆》里的一句话：我爱量化，我怕他完了！更多相关量化内容更多相关资料请见下方文章卡片，另外还有一个周更的量化公Z号『量化君也』，专注于量化策略分享/交流/社群，欢迎来玩~你见过哪些怪异的量化交易策略？你见过哪些耳目一新的量化交易策略？各位推荐一些量化投资的书籍、资料和网站啊？量化模型的建型过程是怎么样的呢？量化君也：复现网红阻力支撑指标RSRS，手把手教你构建大盘择时策略量化君也：261个策略/指标，量化萌新可以在这本量化神作中学到的量化君也：如何打造「量化策略兵器库」，策略开发效率提高10倍？量化新手找因子如何入门？万能的知乎量化，有哪些可以挖掘因子、研发因子、学习新因子的路径？",
        "url": "https://zhuanlan.zhihu.com/p/664238706",
        "voteup_count": 3,
        "verb": "MEMBER_VOTEUP_ARTICLE"
    },
    "1698556993042": {
        "created_time": 1698556993,
        "content": "我之前介绍分享过不少量化策略了，但是着重点是在标的筛选和进出场时机的把握，仓位一般都是等权重或是等手数，较少涉及到仓位管理，为了填补这方面的空白，先拿菜场大妈策略下手，唠唠如何在股票清单相同的情况下，通过仓位管理，达到优化策略表现的目的，从十年100倍提升到十年160倍。先拿菜场大妈策略开刀的原因，是因为它是目前个人宽客非常喜欢的热门小市值策略，但很多公布出来的小市值类型的策略，里面普遍都是对个股进行等权处理，也就是对于筛选出来的小盘股，每支股票都是买入相同的金额，这种处理的确是很方便，但不够圆润，于是乎，盘他！先给不清楚前情的小伙伴说说菜场大妈选股策略的构建思路，最核心的选股思路归结起来就七个字：质好价低市值小。质好，就是筛选质量好、基本面好的股票。最初的版本只使用了“股息率”这个因子，能真金白银分红的企业应该不会差到哪里去，后来的改进版本当中，为了筛选更优质的股票，同时使用股息率和PEG因子(市盈率相对盈利增长比率)。价低，就是筛选质好股票中价格低的股票，最初的版本中是股价不能超过9元，“9元”这个设置除了测试效果好之外，还有一个用意就是，方便小资金的个人宽客使用该策略，买入1手股票加上交易费用和滑点，最多才900块出头，选股10支，还不到1w，真的是非常滴亲民接地气。由于A股最新的“面值1元退市”规则，于是在改进版当中加入了最低限价2元，也就是股价要在2~9元之间。市值小，顾名思义，也就是筛选出前两步“质好价低”中市值最小的N支股票，作为最终的目标持仓。您瞧，虽然策略的名称看起来很俗气，但却利用了两个被金融专家孜孜不倦研究的金融异象——小市值和低价股，有明显的盈利逻辑。对菜场大妈策略进行回测，每个月第一个交易日调仓，剔除ST、停牌、涨跌停等股票之后，最终选择符合上述条件的10支股票，等权分配资金，正常费率滑点，回测绩效如下，对策略更加详细的描述和回测请见之前的文章《量化交易野路子：菜场大妈选股策略（10年100倍）》。对数轴方便看超额收益从回测图表中看出，从2013年至今，菜场大妈策略这10年来取得了10932.19%的累计收益，十年100倍，年化收益是56.48%，夏普率是2.03，最大回撤为31.19%，作为一个简单的入门级策略，这个收益情况算是不错的了，而现在，咱想要它变得更好，改进的方向就是仓位管理。原始版菜场大妈主要解决的是选什么股票的问题，仓位管理解决的是给这些选定的股票如何分配权重的问题。从解决仓位管理普适性问题出发，假设选股策略选出了n支股票S_1~S_n，给每支股票分配的权重分别是w_1~w_n，假设每支股票未来的预期收益分别为R_1~R_n，那么整个组合的收益可以表示为R=w_1*R_1+w_2*R_2+...+w_n*R_n。这个组合收益R就是所有仓位管理问题的起点，你希望组合收益呈现出一种什么样的状态呢？是风险一定的情况下收益最高，还是收益一定的情况下风险最小，还是组合里每个股票冒同样的风险，亦或是收益除以风险的夏普值更高~~要回答这个问题，就要请出现代金融理论和资产组合理论的先驱马科维茨老爷子(Markowitz)，马老爷子1952年在其经典之作《PortfolioSelection》提出了均值-方差模型，创造性地将数学引入到金融投资领域当中，从数学层面上解决了资产选择和仓位分配的问题。马老爷子凭借着对现代金融经济学理论的开拓性研究，以及提供了切实可用的金融资产收益与风险的衡量工具，获得了1990年的诺贝尔经济学奖。可惜的是，马老爷子今年6月在圣地亚哥仙逝了，享年95岁，但留下的理论工具依然熠熠生辉。咱这次要用到的就是其中的最小方差组合理论，要看懂的话真的不难，只要明白数学期望、方差和协方差的基本定理与性质就可以了。马老爷子用投资回报的期望值表示组合投资收益率，也就是咱之前已经写出的表达式：R=w_1*R_1+w_2*R_2+...+w_n*R_n；用组合收益R的方差(或标准差)表示组合收益的风险，那将R的式子代入到方差(Variance)的计算公式当中，则可以将式子展开成各个股票收益相关的表达式。其中Var(R_i)表示第i支股票收益率的方差，Cov(R_i,R_j)表示第i支股票和第j支股票收益率的协方差，特别地，Cov(R_i,R_i)=Var(R_i)，如果不明白的话，度娘一下方差和协方差的计算公式就一清二楚了。于是乎，展开式的第二行就统一用协方差表示，每支股票两两求协方差后与各自权重相乘，最终全部加总。菜场大妈策略是选10只股票，那对应的Var(R)展开是有10x10=100个子项。为了表达的简洁性，最终表示为向量矩阵的乘积形式，其中W为n维列向量(w_1,w_2,...,w_n)，左上角有个T是表示转置成行向量，Ω为股票之间收益率的协方差矩阵(nxn维)。1xn维的列向量乘以nxn维矩阵，再乘以nx1维行向量，最终的结果是一个标量数值，就是整个组合的风险，咱就是希望找到这个最合适的权重向量W，使得整个组合风险最小化，形成方差/风险最小的投资组合。怎么找到这个最优权重向量W呢？一般在量化实践当中，咱直接调用数学优化模块进行寻优处理，例如Python当中的scipy库的optimize模块，以Var(R)作为目标函数，给出对应的约束条件，然后它就会给你找出Var(R)最小值对应的那组权重。就跟使用ChatGPT一样，你给它描述任务、背景和条件，它就能给你提供解决方案。在真正开始实战之前，还要提一嘴最小方差模型的致命缺陷，那就是如果有一个股票之前的股价波动相对较小的话，那它的权重会变得非常大，反之，之前波动大的股票权重会非常小。用一个例子进行解释，假设有三支股票，为了简单起见，假设它们之间两两不相关，也就是相关系数与协方差皆为0，那收益率的协方差矩阵就是对角元素为各自收益率方差的对角矩阵，那可以显式获得最优权重的解析解。其中V_i就表示第i支股票收益率的方差(风险)，从上面的式子可以看出，股票的权重与其方差成反比，要是股价波动小的话，权重会变得非常高。如果单纯是根据最小方差组合模型求解权重的话，经常会出现单个股票权重在40%~50%之上，另外一些股票权重在1%之下，如果资金量小的话，低价股也买不进一手，根本成交不了。所以在量化实战当中，可以人为设定单只个股的权重上下限，指定要在这个权重范围内求解最小方差对应的权重，于是乎，用带权重上下限约束的最小方差组合模型，确定菜场大妈策略每期选出的那10支股票的权重，其他设置不变，重新回测一遍，绩效如下所示。对数轴方便看超额收益年化收益率从56.48%提升到了62.81%，累计收益从十年100倍提高到了十年160倍，夏普率从2.03提高到了2.30，再看看今年年初至今的表现，菜场大妈原版策略目前累计收益是56.61%，马科维茨版的是60.19%，也是高出了一头，说明用马科维茨最小方差组合模型进行仓位分配，还是明显起到了改进策略的作用，没有白折腾。菜场大妈策略原版：菜场大妈策略马科维茨版：细心的小伙伴可能发现了，原版策略的波动率是0.258，最大回撤是31.19%，马科维茨版的波动率是0.255，最大回撤是31.31%，虽然整体波动率是下降了，起到了“最小方差”的作用，但是降低幅度不明显，而且最大回撤还略微增加了，为啥出现这样的情况呢？那是马科维茨均值-方差模型最最最致命的“缺陷”，在计算组合收益R时，要输入的是股票的“预期收益”，那是未来的事情，或者是咱也不知道股价的真实概率分布，只好使用历史数据代替，过去的波动未必代表未来的波动，就难以起到方差最小化的作用。但是，如果是同时持仓股票和债券，给这俩分配权重，那很明显，股票与债券的相关性没有股票与股票之间高，并且债券的波动率要明显低于股票，那最小方差模型肯定会将大部分权重给予债券，债券的低波动是持续性的，那就可以起到最小方差的作用，这也从侧面说明了降低整体波动最好是多种低相关资产进行组合。那马科维茨版的菜场大妈策略为什么会比以前明显收益更高了呢？那是因为长期来看，低波动股票的收益整体要比高波动的股票要高，国内外股市普遍如此，又被称为“低波异象”。最小方差组合模型更倾向于将高权重分配给低波动股票，对于之前的等权组合而言，相当于是提高了低波动股票的权重，降低了高波动股票的权重，把更多的权重分配给了未来预期收益更好的股票，因此通过仓位管理提高了整个组合的收益。所以啊，在做仓位管理的时候，也不一定要用马科维茨的模型，只要人为地提高低波动股票的权重，降低高波动股票的权重，也能达到类似的效果，只不过马老爷子的模型算得更合理一些，因为他还考虑了组合股票之间的相关关系，比单独根据波动率因子分配的要强上一丢丢。以上内容纯粹是个人猜想和探究，用以抛砖引玉，下期见~PS：本文『马科维茨版的菜场大妈策略』试验源码、使用说明和相关资料已分享至『量化藏经阁』和『量化藏经阁Max』社群内，群友请在社群量化兵器库原路径中自取。我是@quantkoala，一枚大写的量化/程序化策略源码捕手，喜欢全方位收集分享市面上主流的策略源码（股票+期货+外汇），在『量化藏经阁』和『量化藏经阁Max』社群（入口）中，持续分享量化策略源码和量化知识等干货（目前已分享200+套精品策略），欢迎关注点赞&amp;联系沟通，探讨共赢&amp;成果共享，相互交流&amp;共同进步！！！常在线，多交流，多沟通！！！更多相关资料请见下方文章卡片，另外还有一个持续更新的公Z号『量化君也』，专注于量化策略分享/交流/社群，欢迎来玩~quantkoala：私募奇葩要求，投资经理3周须开发4000个量化因子，手把手教你4行核心代码轻松应对quantkoala：如何避开国内量化机构的这些坑？血泪经历盘点quantkoala：错错错，都是量化交易砸盘的错quantkoala：量化交易野路子：菜场大妈选股策略（10年100倍）quantkoala：36分钟，6万次报撤单，1手委托亏损400万，量化交易实盘中潜在的那些坑quantkoala：注册制全面推行后，对量化交易的5点影响quantkoala：做量化交易发愁写代码？一招教你白嫖GPT-4智能编程神器quantkoala：2022年量化文章合辑|量化投资从入门到不放弃quantkoala：如何打造「量化策略兵器库」，策略开发效率提高10倍？222赞同·10评论文章227赞同·10评论文章229赞同·10评论文章231赞同·10评论文章237赞同·10评论文章240赞同·10评论文章259赞同·10评论文章260赞同·10评论文章260赞同·10评论文章261赞同·10评论文章266赞同·10评论文章268赞同·10评论文章269赞同·10评论文章272赞同·10评论文章273赞同·10评论文章276赞同·10评论文章281赞同·10评论文章281赞同·12评论文章284赞同·12评论文章284赞同·12评论文章289赞同·12评论文章298赞同·12评论文章299赞同·12评论文章306赞同·12评论文章316赞同·12评论文章324赞同·12评论文章quantkoala：“28岁了，做了两年量化，没有做出策略，该怎么办？”47赞同·2评论文章55赞同·2评论文章55赞同·2评论文章57赞同·2评论文章61赞同·2评论文章61赞同·2评论文章64赞同·2评论文章68赞同·2评论文章69赞同·2评论文章quantkoala：探索利用价格概率密度函数，构建趋势突破策略quantkoala：两个简单的GARP因子，帮这位量化基金经理，跻身同类Top10（含复现）quantkoala：又来唠一个另类异质量化策略：20后的Trendflex策略quantkoala：CTA策略中的Alpha：期限结构之展期收益率策略55赞同·10评论文章quantkoala：ETF轮动策略在阻力支撑相对强度RSRS指标加持下起飞（年化91.6%）93赞同·10评论文章quantkoala：唠一个异质化另类量化策略：K线面积交易法（盈亏比1.83）122赞同·22评论文章quantkoala：Barra太复杂，唠一个适合萌新Quant上手的量化基本面多因子模型F-Score（策略Alpha：23.4%，附源码）135赞同·7评论文章quantkoala：手把手教你，利用机器学习模型，构建量化择时策略（附全流程代码）quantkoala：唠一唠曾在全球量化策略热榜上排名第9的TrendModelSys策略(年化34.3%)366赞同·18评论文章quantkoala：八年实盘100万到1000万的跨周期突破策略源码Q01174赞同·26评论文章",
        "url": "https://zhuanlan.zhihu.com/p/663936942",
        "voteup_count": 18,
        "verb": "MEMBER_CREATE_ARTICLE"
    },
    "1698111689637": {
        "created_time": 1698111689,
        "content": "[{'content':'今天过节，大伙儿都早点儿下班吧，关爱程序员，减少加班~#程序员节','fold_type':'raw','own_text':'今天过节，大伙儿都早点儿下班吧，关爱程序员，减少加班~#程序员节','text_link_type':'internal','title':'','type':'text'},{'cropped_url':'https://picx.zhimg.com/100/v2-9f96a697f6ef76f63fee9f39a065ff99_720w.jpg','height':1080,'is_gif':False,'is_long':False,'is_watermark':True,'original_url':'https://pic1.zhimg.com/100/v2-44f05f1706b60e3d2fbc70eb173ce3dc_r.jpg','thumbnail':'','type':'image','url':'https://pic2.zhimg.com/100/v2-abb1e4672a0ae2c865d076b250cb636b_720w.jpg','watermark_url':'https://pic2.zhimg.com/100/v2-abb1e4672a0ae2c865d076b250cb636b_720w.jpg','width':1920},{'cropped_url':'https://pica.zhimg.com/100/v2-8f9601d0a4871416580af0ff1357a656_720w.jpg','height':405,'is_gif':False,'is_long':False,'is_watermark':True,'original_url':'https://picx.zhimg.com/100/v2-8439d9cdeb1bb521d41b3a6659946d5d_r.jpg','thumbnail':'','type':'image','url':'https://pic2.zhimg.com/100/v2-ed01ff2359c0a0d9b6bc6a26363bf035_720w.jpg','watermark_url':'https://pic2.zhimg.com/100/v2-ed01ff2359c0a0d9b6bc6a26363bf035_720w.jpg','width':720},{'cropped_url':'https://pic4.zhimg.com/100/v2-ae48814a8264a0b81b2ac08eca3bb9e9_720w.jpg','height':480,'is_gif':False,'is_long':False,'is_watermark':True,'original_url':'https://picx.zhimg.com/100/v2-77992284fcef01e645abaecdac0ec6f3_r.jpg','thumbnail':'','type':'image','url':'https://picx.zhimg.com/100/v2-8e865c01172d5fb97b6e5d0357a697f1_720w.jpg','watermark_url':'https://picx.zhimg.com/100/v2-8e865c01172d5fb97b6e5d0357a697f1_720w.jpg','width':585},{'height':499,'is_gif':False,'is_long':False,'is_watermark':True,'original_url':'https://pic2.zhimg.com/100/v2-ea850f604c9a0e2943f3afacb7496193_r.jpg','thumbnail':'','type':'image','url':'https://pic1.zhimg.com/100/v2-9bc08c689b77ff487f2a24e257914274_720w.jpg','watermark_url':'https://pic1.zhimg.com/100/v2-9bc08c689b77ff487f2a24e257914274_720w.jpg','width':720}]",
        "url": "https://api.zhihu.com/pins/1700084325326995456",
        "verb": "MEMBER_CREATE_PIN"
    },
    "1698074340577": {
        "created_time": 1698074340,
        "content": "在金融投资和量化交易领域，机器学习算法越来越受欢迎，也越来越普遍，因为咱人类一般通过观察能发现因果之间的线性关系，而非线性关系就不得劲儿了，于是乎，就要靠着这些机器学习算法帮助咱做出更明智的投资交易决策。在这篇文章里面，唠唠我之前在金融投资和量化交易当中，常用的并且效果还不赖的10大机器学习算法，会大概讲述其基本工作原理、用法用途和代码案例，主要是为量化萌新们起到“算法清单”的作用，文章篇幅有限，难以面面俱到，还望海涵~开整~~一、线性回归(Linearregression)线性回归应该可以说是最常用的一种统计模型了，高中就接触过的最小二乘法OLS就属于线性回归，你瞧，这也算是早期接触机器学习的案例了。线性回归基于一个或多个自变量预测因变量的值，它之所以被称为“线性”，那是因为它假设因变量和自变量之间的关系是线性的，形式如y=a0+a1*x1+a2*x2+...+an*xn，其中x是自变量，y是因变量，a就是回归系数，a0又被称为截距。在金融投资和量化交易领域，线性回归经常被用来建模和预测金融时间序列/横截面数据，比如证券价格、因子收益、汇率和利率等等。它可以用来识别不同变量/因子之间的关系，并基于这些关系对未来值进行预测。线性回归主打的优点就是其简单性和可解释性，不信你瞧，咱常见的资本资产定价模型（CAPM）、套利定价模型（APT）和Fama-French三因子等等模型都是表达成这种形式。线性回归模型除了应用广泛之外，还非常容易实现，即使在大数据集上，它的训练速度也相对较快，并且还可以通过使用虚拟变量来处理缺失数据和分类变量。现在使用这些机器学习算法已经非常方便了，都是封装好的库（例如scikit-learn），直接调用就可以了，下面来看看线性回归的实例源码。importnumpyasnpfromsklearn.linear_modelimportLinearRegression#构建数据样本X=np.array([[1,2],[3,4],[5,6],[7,8]])y=np.array([1,2,3,4])#创建线性回归模型model=LinearRegression()#用数据样本训练模型model.fit(X,y)#用训练好的模型去预测样本predictions=model.predict(X)#打印输出print(&#39;预测：&#39;,predictions)print(&#39;系数：&#39;,model.coef_)print(&#39;截距：&#39;,model.intercept_)输出结果：预测：[1.2.3.4.]系数：[0.250.25]截距：0.24999999999999956这段代码是对X数组中的数据进行线性回归模型拟合，y数组作为目标变量(因变量)，可以看出X有4个样本点，每个样本有2个特征，会自动学习出2个回归系数和1个截距，最终的训练模型为y=0.25+0.25x1+0.25x2。这里特别说明的是，虽然上面的代码简单，但现在的机器学习库的使用流程基本都是一样的：先从库(sklearn)中导入需要的模型(LinearRegression)，然后导入数据进行训练(fit)，最后便可以使用训练好的模型对新数据进行预测(predict)，如果觉得有需要，可以查看模型的关键参数(coef_和intercept_)。下文所有算法模型的建模流程都是遵循这种三板斧流程，不再赘述。不过一般情况下，训练模型用的数据集称为训练集，给训练好的模型进行预测的数据集称为测试集，两个数据集一般数据是不重叠、没有交集的，咱这里是偷懒了，请注意区分。二、逻辑回归(Logisticregression)不要看到这个算法里面有“回归”(regression)的字样，就以为它是像线性回归那样用来完成回归任务的，其实它主要是被用来完成分类任务的。通常是基于一个或多个自变量预测二元结果的概率。它的模型结构是y=1/(1+exp(a0+a1*x1+a2*x2+...+an*xn))，就是在线性回归的基础上，套上了一层Sigmoid函数y=1/(1+exp(x))，无论exp(*)当中的数值是什么范围，都能将y限制到0~1之间，很好地完成二分类任务。在金融投资和量化交易领域中，逻辑回归就是经常被用于分类任务，例如证券价格是上涨还是下跌、财务报表当中是否存在欺诈行为或者企业净利润率是否超额上升。逻辑回归的主要优势和线性回归一样，实现和解释起来都相对简单，即使在大型数据集上训练也非常快速。除此之外，逻辑回归具有“概率性”的特性，这意味着它可以输出概率形式的预测结果，而不仅仅是二元预测，这一点在量化交易当中非常有用，能衡量其中不确定性或风险水平。咱来看看逻辑回归的使用实例，如下所示，从整个流程来看，跟线性回归模型是一样的，只不过对于分类任务，y的标签数值要改为0或1，用来表示类别。importnumpyasnpfromsklearn.linear_modelimportLogisticRegression#构建数据样本X=np.array([[1,2],[3,4],[5,6],[7,8]])y=np.array([0,1,0,1])#创建逻辑回归模型model=LogisticRegression()#训练模型model.fit(X,y)#对数据进行预测量predictions=model.predict(X)#打印预测结果print(predictions)三、决策树(Decisiontrees)决策树之所以被称为“决策”树，顾名思义，能根据数据集的特征进行预测，它通过数据构建一个类似树状的决策模型来工作，每个分支代表不同的决策或结果。在金融投资和量化交易领域中，决策树通常被用于分类任务。决策树的主要优势除了相对简单易懂和解释较强外，关键它还能够处理复杂的数据集，并能够识别特征与目标变量之间的非线性关系。不过，如果决策树没有经过适当的修剪，可能会出现过拟合的问题，从而降低其泛化能力。决策树的使用案例如下所示，流程跟上面两种算法是一样的，注意是分类任务就好。importnumpyasnpfromsklearn.treeimportDecisionTreeClassifier#构建样本数据X=[[0,0],[1,1]]Y=[0,1]#创建决策树分类器clf=DecisionTreeClassifier()#训练模型clf=clf.fit(X,Y)#打印预测结果print(clf.predict([[2.,2.]]))对了，你还可以指定用于拆分树的准则类型，例如“gini”或“entropy”，并设置其他参数，如树的最大深度或叶节点所需的最小样本数，在scikit-learn文档中可以找到完整描述。https://scikit-learn.org/stable/modules/tree.html四、随机森林(Randomforests)随机森林属于上面刚介绍的决策树的扩展，基于集成学习的原理，用于进行更强大和可靠的预测。它通过创建一组决策树，并使用每棵树所做预测的平均值来进行最终预测，就类似于现实当中咱一群人投票，然后少数服从多数那样。随机森林一般也是被用于分类任务，一般具有比较高的准确性，并且往往比单个决策树具有更好的泛化能力。不过，与单个决策树相比，随机森林的解释性相对差一些，因为预测是基于许多树的平均值，而不是单个树。在使用当中，从sklearn里面导入RandomForestClassifier模型后，需要设置森林中树的数量(n_estimators)，树的最大深度(max_depth)和随机种子(random_state)，其他的部分，就是跟传统的三板斧流程一样的了。importnumpyasnpfromsklearn.ensembleimportRandomForestClassifier#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#创建随机森林模型model=RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)#训练模型model.fit(X_train,y_train)#预测新数据predictions=model.predict(X_test)#打印预测结果print(predictions)需要特别说明的是，load_data()是抽象出来的函数，需要自己根据自身应用情况实现，主要目的是用来加载训练集数据(X_train)和标签(y_train)、测试集数据(X_test)和标签(y_test)，组织形式跟上面介绍过的3个算法是一样的，如果当前自己还没有确切建模任务的话，可以根据我之前的两篇文章《手把手教你，利用机器学习模型，构建量化择时策略》和《投资经理3周须开发4000个量化因子，手把手教你4行核心代码轻松应对》中的数据准备部分构建因子数据和打上对应的标签。手把手教你，利用机器学习模型，构建量化择时策略（附全流程代码）私募奇葩要求，投资经理3周须开发4000个量化因子，手把手教你4行核心代码轻松应对如果也不想自己组织数据，想马上就开箱使用，那可以直接使用sklearn机器学习库datasets模块，里面自带了各种机器学习任务需要用到的数据集，首先你可以使用make_regression或make_classification函数自定义生成自己需要的回归/分类数据集，其次你也可以使用现成的数据集，例如回归任务常用的糖尿病数据集(load_diabetes)，分类任务的鸢尾花数据集(load_iris)。私募奇葩要求，投资经理3周须开发4000个量化因子，手把手教你4行核心代码轻松应对如果也不想自己组织数据，想马上就开箱使用，那可以直接使用sklearn机器学习库datasets模块，里面自带了各种机器学习任务需要用到的数据集，首先你可以使用make_regression或make_classification函数自定义生成自己需要的回归/分类数据集，其次你也可以使用现成的数据集，例如回归任务常用的糖尿病数据集(load_diabetes)，分类任务的鸢尾花数据集(load_iris)。就以随机森林这次的分类任务为例，使用鸢尾花数据集(load_iris)，咱先看一下具体的数据形式。importnumpyasnpimportpandasaspdfromsklearnimportdatasetsiris=datasets.load_iris()#导入鸢尾花数据data=iris[&#39;data&#39;]#数据label=iris[&#39;target&#39;]#数据对应的标签feature=iris[&#39;feature_names&#39;]#特征的名称df=pd.DataFrame(np.column_stack((data,label)),columns=np.append(feature,&#39;label&#39;))df.iloc[[0,1,60,61,120,121],:]#分别展示类别为0、1、2的样本iris包含了150个鸢尾花的数据，其中每个样本有4个特征，分别为萼片长度、萼片宽度、花瓣长度和花瓣宽度，以及对应的类别标签，label的0、1、2分别对应花的品种IrisSetosa、IrisVersicolour、IrisVirginica）。于是乎，要在随机森林当中使用这个数据集来训练和测试模型，只需要将应用实例当中的这句代码#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()修改为fromsklearnimportdatasetsfromsklearn.model_selectionimporttrain_test_split#加载训练集和测试集数据iris=datasets.load_iris()X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,test_size=0.2)为了方便阐述和展示，下文依旧使用抽象函数load_data()表示训练集和测试集数据的加载，不再赘述。五、K最近邻（KNN）K最近邻（K-NearestNeighbors，KNN）是一种常用于分类和回归任务的机器学习算法，它大概的原理是通过找到离给定数据点最近的K个数据点，并利用这些数据点的类别或数值来进行预测。相信大多数人都听过这种说法，“你的收入就是身边5位好友收入的平均值”，KNN贯彻的就是这种“人以群分，物以类聚”的理念。在金融投资和量化交易领域中，KNN通常用于分类任务居多，也可以用于回归。KNN的主要优势之一是相对简单易懂，并且容易实现，对缺失值不太敏感，最大的缺点就是，它对于K值的选择比较敏感。除此之外，在特征/因子数量相对于样本数量过大的情况下可能表现比较拉胯，在大型数据集上进行KNN预测也可能需要比较大的计算量。importnumpyasnpfromsklearn.neighborsimportKNeighborsClassifier#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#创建KNN模型model=KNeighborsClassifier(n_neighbors=5)#训练模型model.fit(X_train,y_train)#预测新数据predictions=model.predict(X_test)#打印预测结果print(predictions)六、K均值聚类算法(K-Means)说完KNN，就顺道儿来说一下它的亲戚K-Means，从称呼上看起来很像，底层原理也很像，但干的却是不一样的活儿。K-Means一般用于聚类(clustering)任务，而KNN一般用于分类(classification)任务，虽然是一字之差，但用途却不一样。咱可以先把实例代码贴出来，你就会发现它跟别的算法代码有个显著的区别。importnumpyasnpfromsklearn.clusterimportKMeans#构建样本数据X=np.array([[1,2],[1,4],[1,0],[4,2],[4,4],[4,0]])#创建KMeans模型model=KMeans(n_clusters=2,random_state=0,n_init=&#39;auto&#39;)#训练模型model.fit(X)#预测新数据predictions=model.predict([[0,0],[4,4]])#打印预测结果print(predictions)看见木有，别的算法一般训练模型时都需要同时输入特征/因子数据X和标签数据y，而K-Means只需要输入特征/因子数据X，前者这种训练方式被称为监督学习(Supervisedlearning)，后者则被称为无监督学习(Unsupervisedlearning)，前者就相当于让你自学的时候，既发给你试题，也发给你参考答案，后者是只发试题，木有答案。那有什么用呢？也是起到“人以群分，物以类聚”的划分作用，因此K-Means叫聚类算法，比如说现在A股有5000多支股票，申万把它们划分为31个行业，你觉得这样划分不合适，可以给它们设定不同的属性/因子和想分成多少个行业/概念/风格/板块(例如上面实例的聚类数是2)，K-Means算法就可以把这5000多支股票按自己的要求划分出来，在每个簇当中，里面的股票在你设定属性/因子方面肯定都是极其相似的，属于你自己的行业/概念/风格/板块。很多时候，你会惊叹，八竿子打不着的股票怎么会在这些方面这么相似。七、支持向量机（SVM）支持向量机（SupportVectorMachines，SVM）最初的设计是用来解决二分类问题，后来扩展到多分类问题，比如说之前开发的大盘择时策略“预测沪深300指数涨跌”就属于典型的二分类问题，“涨”是一个类别，“跌”就是另一个类别。它通过寻找一个最大间隔超平面将两类样本线性区分开来，并且保证两侧样本的最近边缘点到这个平面的距离是最大的，由于最大间隔超平面仅取决于两个类别的边缘点，这些点就被称为支持向量，这就是“支持向量机”名称的由来。如果数据点在原始空间不可分的话，就将低维不可分的数据映射到高维线性可分，于是乎，SVM的主要优势之一就是能够处理高维数据，并且能识别特征与目标变量之间的复杂关系。不过，与其他一些机器学习算法相比，SVM的训练计算量可能更大，并且由于基于复杂的优化问题，解释性就相对差一些。对了，为了将数据从低维映射到高维，SVM中核函数的选取就非常关键，常用的核函数有线性核、多项式核、高斯核（RBF核）和Sigmoid核。importnumpyasnpfromsklearn.svmimportSVC#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#创建SVM模型model=SVC(kernel=&#39;linear&#39;,C=1.0)#训练模型model.fit(X_train,y_train)#预测新数据predictions=model.predict(X_test)#打印预测结果print(predictions)八、朴素贝叶斯(NaiveBayes)朴素贝叶斯是一种基于贝叶斯定理进行预测的机器学习算法，它之所以被称为“朴素”是因为它假设数据集当中的所有特征都是相互独立的，而在现实世界的数据中当然肯定不是这样的。尽管有这个假设，朴素贝叶斯算法通常用起来效果也不错，并且在金融投资和量化交易当中经常使用。朴素贝叶斯算法常被用于分类任务，比如预测指数第二日涨跌、财经新闻的正负面情或者财务报表是否掺假。朴素贝叶斯算法的主要优势之一就是其简单性和易于理解了，就连很多成功学文章和书籍中，都经常倡导要“贝叶斯式”思考。这个模型训练起来也非常快，即使是在大型数据集上。并且，当底层数据受到某些类型的噪声干扰影响，或者特征数量相对于样本数量过大时，朴素贝叶斯算法往往也都有良好表现。importnumpyasnpfromsklearn.naive_bayesimportGaussianNB#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#创建朴素贝叶斯分类器model=GaussianNB()#训练模型model.fit(X_train,y_train)#预测新数据predictions=model.predict(X_test)#打印预测结果print(predictions)九、神经网络(Neuralnetworks)神经网络是一种受到人脑结构和功能启发而研发出来的机器学习算法，模型结构由大量相互连接的节点(神经元)组成，模拟人脑的机制用于处理和传输信息。神经网络特别适用于涉及模式识别和预测的任务，并且已被广泛应用于各种领域和场景，取得了非常显著的成果。神经网络模型在回归和分类任务上都非常支棱，只需要人为地确定模型结构，然后就能够在没有显式编程的情况下学习、迭代和适应新数据，它还可以处理大型和复杂的数据集，并能够识别特征与目标变量之间的非线性关系。与其他一些机器学习算法相比，神经网络的训练可能需要消耗更多的计算资源，并且由于其中复杂的网络结构，因此可解释性就差很多，如果设计和训练不当的话，神经网络非常容易过拟合。importnumpyasnpfromtensorflow.keras.modelsimportSequentialfromtensorflow.keras.layersimportDense#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#创建神经网络分类器model=Sequential()model.add(Dense(8,input_dim=4,activation=&#39;sigmoid&#39;))model.add(Dense(1,activation=&#39;sigmoid&#39;))model.compile(loss=&#39;binary_crossentropy&#39;,optimizer=&#39;adam&#39;,metrics=[&#39;accuracy&#39;])#训练模型model.fit(X_train,y_train,epochs=20,batch_size=32)#预测新数据predictions=model.predict(X_test)#打印预测结果print(predictions)十、集成学习(Ensemblelearning)集成学习(Ensemblelearning)并不是特指某一个算法，而是一个算法大类，或者说是训练和组合模型的思路或方法。在机器学习当中，单个模型运行时可能表现没那么好，但同时将多个模型组合起来，“三个臭皮匠顶个诸葛亮”，就会变得非常强大，这种多个基础模型/算法的组合，就被称为集成学习。集成学习一般分为两大类：Bagging(装袋法)和Boosting(提升法)。这两种方法都是将多个弱模型组合在一起，形成一个强模型，但它们之间最明显的区别是，Bagging中的多个弱模型都是并行单独训练，然后再组合在一起，而Boosting是串行训练，下一级弱模型是根据前一级弱模型的“残差”针对性训练，用来提升上一级的“短板”，最终再组合在一起。其实集成学习还有更为复杂的Stacking(堆叠法)和Cascading(级联法)，有兴趣的话，可以自己去探究一下。Bagging模型结构：Boosting模型结构：Bagging集成学习其实咱之前已经见过了，那就是随机森林，在金融投资和量化交易领域，Bagging用得最多的就是它。Boosting集成学习就比较多了，常见的有：梯度提升树GBDT、自适应提升算法Adaboost、极限梯度提升算法XGBoost和轻量级梯度提升算法LightGBM。以前常用XGBoost组合多因子模型，现在多流行用LightGBM，那就以LightGBM作为实例展示吧。importnumpyasnpimportlightgbmaslgb#加载训练集和测试集数据X_train,y_train,X_test,y_test=load_data()#训练模型gbm=lgb.train(params={&#39;learning_rate&#39;:0.05,&#39;lambda_l1&#39;:0.1,&#39;lambda_l2&#39;:0.2,&#39;max_depth&#39;:3,&#39;objective&#39;:&#39;multiclass&#39;,&#39;num_class&#39;:3},train_set=lgb.Dataset(X_train,label=y_train))#预测新数据predictions=gbm.predict(X_test)predictions=[list(v).index(max(v))forvinpredictions]#打印预测结果print(predictions)量化交易领域的10大常用机器学习算法就盘点完了，不知道你有没有发现，再复杂的机器学习算法，利用现成的机器学习算法库(如sklearn)，按照“三板斧”流程，十几二十行代码就可以建模完毕，麻麻再也不用担心咱的算法实现。这就是本文想要达到的目的，以后大伙儿大部分时间只需要专注于量化任务拆解和数据整理，是分类任务(如预测涨跌)，还是回归任务(如预测涨跌幅)，接着把特征/因子数据整理好，按照这篇“机器学习算法清单”的索引，按需按代码实例使用相应算法就搞掂了，顺藤摸瓜，按图索骥。内容来源/参考：ChristopheAtten，2022.12，《Top10machinelearningalgorithmsinFinance》ChainikaThakar，2023.01，《Top10MachineLearningAlgorithmsForBeginners》机器之心，2019.03，《机器学习必学10大算法》楷哥，2020.10，《集成学习》周志华，2016.01，《机器学习》我是@quantkoala，一枚大写的量化/程序化策略源码捕手，喜欢全方位收集分享市面上主流的策略源码（股票+期货+外汇），在『量化藏经阁』和『量化藏经阁Max』社群（入口）中，持续分享量化策略源码和量化知识等干货（目前已分享200+套精品策略），欢迎关注点赞&amp;联系沟通，探讨共赢&amp;成果共享，相互交流&amp;共同进步！！！常在线，多交流，多沟通！！！更多相关资料请见下方文章卡片，另外还有一个持续更新的公Z号『量化君也』，专注于量化策略分享/交流/社群，欢迎来玩~quantkoala：私募奇葩要求，投资经理3周须开发4000个量化因子，手把手教你4行核心代码轻松应对quantkoala：如何避开国内量化机构的这些坑？血泪经历盘点quantkoala：错错错，都是量化交易砸盘的错quantkoala：量化交易野路子：菜场大妈选股策略（10年100倍）quantkoala：36分钟，6万次报撤单，1手委托亏损400万，量化交易实盘中潜在的那些坑quantkoala：注册制全面推行后，对量化交易的5点影响quantkoala：做量化交易发愁写代码？一招教你白嫖GPT-4智能编程神器quantkoala：2022年量化文章合辑|量化投资从入门到不放弃quantkoala：如何打造「量化策略兵器库」，策略开发效率提高10倍？222赞同·10评论文章227赞同·10评论文章229赞同·10评论文章231赞同·10评论文章237赞同·10评论文章240赞同·10评论文章259赞同·10评论文章260赞同·10评论文章260赞同·10评论文章261赞同·10评论文章266赞同·10评论文章268赞同·10评论文章269赞同·10评论文章272赞同·10评论文章273赞同·10评论文章276赞同·10评论文章281赞同·10评论文章281赞同·12评论文章284赞同·12评论文章284赞同·12评论文章289赞同·12评论文章298赞同·12评论文章299赞同·12评论文章306赞同·12评论文章316赞同·12评论文章324赞同·12评论文章quantkoala：“28岁了，做了两年量化，没有做出策略，该怎么办？”47赞同·2评论文章55赞同·2评论文章55赞同·2评论文章57赞同·2评论文章61赞同·2评论文章61赞同·2评论文章64赞同·2评论文章68赞同·2评论文章69赞同·2评论文章quantkoala：探索利用价格概率密度函数，构建趋势突破策略quantkoala：两个简单的GARP因子，帮这位量化基金经理，跻身同类Top10（含复现）quantkoala：又来唠一个另类异质量化策略：20后的Trendflex策略quantkoala：CTA策略中的Alpha：期限结构之展期收益率策略55赞同·10评论文章quantkoala：ETF轮动策略在阻力支撑相对强度RSRS指标加持下起飞（年化91.6%）93赞同·10评论文章quantkoala：唠一个异质化另类量化策略：K线面积交易法（盈亏比1.83）122赞同·22评论文章quantkoala：Barra太复杂，唠一个适合萌新Quant上手的量化基本面多因子模型F-Score（策略Alpha：23.4%，附源码）135赞同·7评论文章quantkoala：手把手教你，利用机器学习模型，构建量化择时策略（附全流程代码）quantkoala：唠一唠曾在全球量化策略热榜上排名第9的TrendModelSys策略(年化34.3%)366赞同·18评论文章quantkoala：八年实盘100万到1000万的跨周期突破策略源码Q01174赞同·26评论文章",
        "url": "https://zhuanlan.zhihu.com/p/662963894",
        "voteup_count": 51,
        "verb": "MEMBER_CREATE_ARTICLE"
    },
    "1696587575796": {
        "created_time": 1696587575,
        "content": "新闻都看了吧，一小伙国庆期间参加了23场婚礼，随份子如流水一般，直接把钱包整瘪“破产”了。我也参加了不少类似的活动，但受伤的除了钱包之外，还有嘴皮子。咋个回事呢？还不是量化行业带给大众的误解闹的~在外界对量化的报道中，前有量化交易员5000W年终奖，中有头部私募员工一只小猪捐赠1.38个小目标，后有私募大佬豪掷2.85亿买上海豪宅。不明内里的群众一看，哦豁，可以啊，做量化交易够赚钱的啊。这导致了我参加的那些婚礼等活动席间，别人一听说我是干这个行当的，要么沉默，要么眼神发亮，我还要费老劲挨个儿解释，可把嘴皮子给磨破了，霍霍得够呛。真的是谢谢现在的一些媒体了，极大地提高了量化行业从业者，在人民群众眼中的身价，我按自己的视野范围捋一下，“量化高薪”的字眼日常主要出现在这3种场景。一是一些自媒体，特别爱写量化割韭菜、量化高薪等主题的内容，博人眼球，赚取流量收益，赚钱嘛，不寒碜。二呢就是一些卖课的培训机构，某乎、朋友圈和文章尾巴都经常见到他们的引流课广告，一块钱/九块九学量化，然后再让你买几千块上万块的正式课，其中主打的卖点就是学完后，入职量化机构就可以赚xx万高薪，迎娶白富美，走向人生巅峰。第三呢就是一些量化猎头了，特别喜欢po一些动不动就是年薪百万的岗位招聘，话里话外也暗示自己身边的量化群体高薪和经手应聘者的高薪。这种行为在一定程度上也能够理解，为了自己的业绩对真实情况进行了筛选美化，类似于幸存者效应。最反感的就是“挂羊头卖狗肉”，套路跟二房东/中介骗毕业生租房那样。你联系到他，他会给你发精美装修的房间图片，当你兴冲冲去实地看房的时候，他会跟你说“不好意思，刚才那个房子已经租出去了，要不看看别的”，你心想反正来都来了就看看呗，就一步步钻入了江湖人性经验充足者的圈套。不好意思，扯远了，继续说回正题~~正是由于在这些场景里面，量化高薪会高频地出现，像钉子一样深深扎在读者脑海里面，造成了深深的误解。量化高薪吗？肯定会有高薪的案例，但这并不是全部。就跟创业一样，失败者沉默，成功者会被大肆报道，但掩盖不了九死一生的概率。那事情的全貌是什么样子，咱要多去感受一下行业的参差，最让我印象深刻的，是这样一个案例。是一个量化研究员的妻子在知乎上提问，说自己丈夫重点院校毕业，年薪从未突破20W，工作也未见起色，问该如何帮助自己的丈夫。看收入的多少，不能光看金额，还要看具体时间，那是哪一年的收入。我于是翻看问题的日志，发现这是去年11月初的问题，但看完问题的补充说明后我震惊了。重点院校对应的竟然是Top2，那就是清北了，而且还是硕士，还是奥数保送的，在我眼里，这妥妥就是天才级别的了。从毕业就开始在私募做量化研究员，五年时间，公司产品规模从20亿也增加到超过了100亿，竟然年薪还没有超过20W，真的是外婆唱曲儿不看本——就(舅)你TM离谱。这是一个天才在量化行业拿低薪的例子，给我的触动很大，但真实性我无法考证，为了让大伙儿看得更全面更真切，自己的眼界人缘能力有限，只好去找更权威的资料。皇天不负有心人，经过一番搜寻，终于在《中国量化投资白皮书》里找到了这方面的数据，先来看2021年的量化从业人员的薪酬数据。看到了吧，量化行业也是符合二八定律的，高薪的有，普通薪水(相对)才是大部分，从饼图中看出，量化从业者薪酬主要集中在30~100W区间，只有不到16%的人能年薪百万，200万以上的更是凤毛麟角。这基本上就跟IT界的薪酬分布一样了，在薪酬这方面，真的不需要特别高看量化行业的同志们。看完前年的数据，再来看看去年的，去年整体行情不好，呈现出“两端增加，中间减少”的趋势，年薪200W以上和15W以下的人增加了，年薪15W以下的人数占比明显增多，超过了20%，年薪百万以上的人数占比也下降到了11.37%，快成为一九定律了。2022年薪酬数据的覆盖度比2021年的更高，更加全面，因为2022年的有效问卷数是410份，2021年的有效问卷数是235份，这个数值应该比绝大部分人能接触到并且愿意透露薪酬的人数要多得多了，有很强的代表性，想看具体统计方法和说明的，回头可以详看这个报告。量化百万年薪，跟创业的成功概率是差不多的，都是九死一生，对量化行业而言，别妖魔化就行了，美化高看什么的就先不需要了。我是@quantkoala，一枚大写的量化/程序化策略源码捕手，喜欢全方位收集分享市面上主流的策略源码（股票+期货+外汇），在『量化藏经阁』和『量化藏经阁Max』社群（入口）中，持续分享量化策略源码和量化知识等干货（目前已分享200+套精品策略），欢迎关注点赞&amp;联系沟通，探讨共赢&amp;成果共享，相互交流&amp;共同进步！！！常在线，多交流，多沟通！！！更多相关资料请见下方文章卡片，另外还有一个持续更新的公Z号『量化君也』，专注于量化策略分享/交流/社群，欢迎来玩~quantkoala：私募奇葩要求，投资经理3周须开发4000个量化因子，手把手教你4行核心代码轻松应对quantkoala：如何避开国内量化机构的这些坑？血泪经历盘点quantkoala：错错错，都是量化交易砸盘的错quantkoala：量化交易野路子：菜场大妈选股策略（10年100倍）quantkoala：36分钟，6万次报撤单，1手委托亏损400万，量化交易实盘中潜在的那些坑quantkoala：注册制全面推行后，对量化交易的5点影响quantkoala：做量化交易发愁写代码？一招教你白嫖GPT-4智能编程神器quantkoala：2022年量化文章合辑|量化投资从入门到不放弃quantkoala：如何打造「量化策略兵器库」，策略开发效率提高10倍？222赞同·10评论文章227赞同·10评论文章229赞同·10评论文章231赞同·10评论文章237赞同·10评论文章240赞同·10评论文章259赞同·10评论文章260赞同·10评论文章260赞同·10评论文章261赞同·10评论文章266赞同·10评论文章268赞同·10评论文章269赞同·10评论文章272赞同·10评论文章273赞同·10评论文章276赞同·10评论文章281赞同·10评论文章281赞同·12评论文章284赞同·12评论文章284赞同·12评论文章289赞同·12评论文章298赞同·12评论文章299赞同·12评论文章306赞同·12评论文章316赞同·12评论文章324赞同·12评论文章quantkoala：“28岁了，做了两年量化，没有做出策略，该怎么办？”47赞同·2评论文章55赞同·2评论文章55赞同·2评论文章57赞同·2评论文章61赞同·2评论文章61赞同·2评论文章64赞同·2评论文章68赞同·2评论文章69赞同·2评论文章quantkoala：探索利用价格概率密度函数，构建趋势突破策略quantkoala：两个简单的GARP因子，帮这位量化基金经理，跻身同类Top10（含复现）quantkoala：又来唠一个另类异质量化策略：20后的Trendflex策略quantkoala：CTA策略中的Alpha：期限结构之展期收益率策略55赞同·10评论文章quantkoala：ETF轮动策略在阻力支撑相对强度RSRS指标加持下起飞（年化91.6%）93赞同·10评论文章quantkoala：唠一个异质化另类量化策略：K线面积交易法（盈亏比1.83）122赞同·22评论文章quantkoala：Barra太复杂，唠一个适合萌新Quant上手的量化基本面多因子模型F-Score（策略Alpha：23.4%，附源码）135赞同·7评论文章quantkoala：手把手教你，利用机器学习模型，构建量化择时策略（附全流程代码）quantkoala：唠一唠曾在全球量化策略热榜上排名第9的TrendModelSys策略(年化34.3%)366赞同·18评论文章quantkoala：八年实盘100万到1000万的跨周期突破策略源码Q01174赞同·26评论文章",
        "url": "https://zhuanlan.zhihu.com/p/659764698",
        "voteup_count": 26,
        "verb": "MEMBER_CREATE_ARTICLE"
    }
}